# -*- coding: utf-8 -*-
"""AirbnbPricePrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wYs9adpTETLWz_Ho48eXIUYNBYfOX7DT

Letâ€™s say we want to build a model to predict booking prices on Airbnb. Between linear regression and random forest regression, which model would perform better and why?

Load Data from Kaggle
"""

#Importing libraries
import numpy as np
import pandas as pd
from math import *
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.offline as py
py.init_notebook_mode(connected=True)
import warnings
warnings.filterwarnings("ignore")
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score, explained_variance_score
from scipy.stats import norm
from scipy import stats

!pip install kaggle

!rm -rf /root/.kaggle

!mkdir /root/.kaggle

!cp kaggle.json /root/.kaggle/

! chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d dipeshkhemani/airbnb-cleaned-europe-dataset

! unzip -o /content/airbnb-cleaned-europe-dataset.zip

df = pd.read_csv('Aemf1.csv')

df.head(10)

"""Data Preprocessing"""

df.isnull().sum()

df = df.drop(columns = ['Shared Room', 'Private Room','Multiple Rooms','Attraction Index','Restraunt Index','Business'], axis=1)
df.head(10)

#Label Encoding
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler

le = LabelEncoder()
df['Day'] = le.fit_transform(df['Day'])
df['Room Type'] = le.fit_transform(df['Room Type'])
df['Superhost'] = le.fit_transform(df['Superhost'])
df['City'] = le.fit_transform(df['City'])

df.head(10)

X = df.drop(columns = ['Price','price_log'], axis =1)
y = df['price_log']

"""Exploratory Data Analysis"""

df.describe()

sns.set(rc = {'figure.figsize':(15,8)})
sns.boxplot( data = y);
plt.show()

sns.countplot(x='Room Type', data = df)
plt.show()
sns.countplot(x='Day', data = df)
plt.show()
sns.countplot(x='City', data = df)
plt.show()

#Correlation between features and price
correlation = X.corrwith(y)
print(correlation*100)

plt.figure(figsize =(12,6))
sns.barplot(x = correlation.values, y=correlation.index, palette ='viridis')
plt.xlabel("Correlation Coefficient")
plt.ylabel("Features")
plt.title("Correlation between Features and Prices")
plt.grid(axis = 'x', linestyle='--',alpha = 0.6 )
plt.show()

#Correlation between features
corr_matrix = X.corr()

plt.rc('font', size = 8)
plt.figure(figsize = (12,12))
plt.imshow(corr_matrix, cmap='coolwarm', interpolation = 'nearest',vmin=1, vmax =1)
plt.colorbar()
plt.title("Correlation Matrix Between Features")
plt.xticks(np.arange(len(corr_matrix.columns)), corr_matrix.columns, rotation =45)
plt.yticks(np.arange(len(corr_matrix.columns)), corr_matrix.columns)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10,10))
sns.distplot(y, fit=norm)
plt.title("Price Distribution Plot",size=15, weight='bold')

df['price_log'] = np.log(df['Price']+1)

plt.figure(figsize=(12,10))
sns.distplot(df['price_log'], fit=norm)
plt.title("Log-Price Distribution Plot",size=15, weight='bold')

plt.figure(figsize=(7,7))
stats.probplot(df['price_log'], plot=plt)
plt.show()

"""Split Training and Testing Data"""

#Split training and testing data
from sklearn.model_selection import train_test_split as tst

X_train, X_test, y_train, y_test = tst(X, y, test_size = 0.2, random_state = 42)
print(X_train.shape)
print(X_test.shape)

"""Model Building
Part 1: Linear Regression
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score

lr = LinearRegression()
lr.fit(X_train, y_train) #training the algorithm

print(lr.intercept_)
print(lr.coef_)

y_pred = lr.predict(X_test)
expl = explained_variance_score(y_pred, y_test)
print(explr)
print(lr.score(X_test, y_test)*100)

"""Part 2: Random Forest Classifier"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import explained_variance_score

rf = RandomForestRegressor(n_estimators=28,random_state=0)
rf.fit(X_train,y_train)
rf_pred =rf.predict(X_test)
expl_rf = explained_variance_score(rf_pred,y_test)
print(expl_rf)
print("Random forest: ",rf.score(X_test,y_test)*100)